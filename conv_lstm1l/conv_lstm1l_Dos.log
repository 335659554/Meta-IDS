F:\anaconda3\envs\py38\lib\site-packages\torch\nn\modules\rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\cudnn\RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Dos1:
Test Loss per batch:0.0007032514549791813
accuracy:1.0,recall:1.0,precision:1.0,f1:1.0
FPR:0.0,FNR:0.0
TP:108.0,FP:0.0,TN:97.0,FN:0.0
-------------------------------------------
Dos2:
Test Loss per batch:0.031902655959129333
accuracy:0.9951219512195122,recall:1.0,precision:0.991304347826087,f1:0.9956331877729258
FPR:0.01098901098901099,FNR:0.0
TP:114.0,FP:1.0,TN:90.0,FN:0.0
-------------------------------------------
Dos3:
Test Loss per batch:7.578169606858864e-05
accuracy:1.0,recall:1.0,precision:1.0,f1:1.0
FPR:0.0,FNR:0.0
TP:119.0,FP:0.0,TN:86.0,FN:0.0
-------------------------------------------
Dos4:
Test Loss per batch:0.0010989432921633124
accuracy:1.0,recall:1.0,precision:1.0,f1:1.0
FPR:0.0,FNR:0.0
TP:112.0,FP:0.0,TN:93.0,FN:0.0
-------------------------------------------
Dos5:
Test Loss per batch:0.0008018919616006315
accuracy:1.0,recall:1.0,precision:1.0,f1:1.0
FPR:0.0,FNR:0.0
TP:52.0,FP:0.0,TN:153.0,FN:0.0
-------------------------------------------
Dos6:
Test Loss per batch:1.4037098480912391e-05
accuracy:1.0,recall:1.0,precision:1.0,f1:1.0
FPR:0.0,FNR:0.0
TP:108.0,FP:0.0,TN:97.0,FN:0.0
-------------------------------------------
Dos7:
Test Loss per batch:0.0008795320754870772
accuracy:1.0,recall:1.0,precision:1.0,f1:1.0
FPR:0.0,FNR:0.0
TP:117.0,FP:0.0,TN:88.0,FN:0.0
-------------------------------------------
Dos8:
Test Loss per batch:0.0019132972229272127
accuracy:1.0,recall:1.0,precision:1.0,f1:1.0
FPR:0.0,FNR:0.0
TP:106.0,FP:0.0,TN:99.0,FN:0.0
-------------------------------------------
Dos9:
Test Loss per batch:3.901726358890301e-06
accuracy:1.0,recall:1.0,precision:1.0,f1:1.0
FPR:0.0,FNR:0.0
TP:125.0,FP:0.0,TN:80.0,FN:0.0
-------------------------------------------
Dos10:
Test Loss per batch:0.0006686443812213838
accuracy:1.0,recall:1.0,precision:1.0,f1:1.0
FPR:0.0,FNR:0.0
TP:106.0,FP:0.0,TN:99.0,FN:0.0
-------------------------------------------
