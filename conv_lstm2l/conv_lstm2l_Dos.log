F:\anaconda3\envs\py38\lib\site-packages\torch\nn\modules\rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\cudnn\RNN.cpp:982.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Dos1:
Test Loss per batch:0.0016602331306785345
accuracy:1.0,recall:1.0,precision:1.0,f1:1.0
FPR:0.0,FNR:0.0
TP:108.0,FP:0.0,TN:97.0,FN:0.0
-------------------------------------------
Dos2:
Test Loss per batch:0.008904954418540001
accuracy:0.9951219512195122,recall:1.0,precision:0.991304347826087,f1:0.9956331877729258
FPR:0.01098901098901099,FNR:0.0
TP:114.0,FP:1.0,TN:90.0,FN:0.0
-------------------------------------------
Dos3:
Test Loss per batch:0.0004285629256628454
accuracy:1.0,recall:1.0,precision:1.0,f1:1.0
FPR:0.0,FNR:0.0
TP:119.0,FP:0.0,TN:86.0,FN:0.0
-------------------------------------------
Dos4:
Test Loss per batch:0.0016398945590481162
accuracy:1.0,recall:1.0,precision:1.0,f1:1.0
FPR:0.0,FNR:0.0
TP:112.0,FP:0.0,TN:93.0,FN:0.0
-------------------------------------------
Dos5:
Test Loss per batch:0.0021569060627371073
accuracy:1.0,recall:1.0,precision:1.0,f1:1.0
FPR:0.0,FNR:0.0
TP:52.0,FP:0.0,TN:153.0,FN:0.0
-------------------------------------------
Dos6:
Test Loss per batch:0.0012056370032951236
accuracy:1.0,recall:1.0,precision:1.0,f1:1.0
FPR:0.0,FNR:0.0
TP:108.0,FP:0.0,TN:97.0,FN:0.0
-------------------------------------------
Dos7:
Test Loss per batch:0.0005801391089335084
accuracy:1.0,recall:1.0,precision:1.0,f1:1.0
FPR:0.0,FNR:0.0
TP:117.0,FP:0.0,TN:88.0,FN:0.0
-------------------------------------------
Dos8:
Test Loss per batch:0.0003611902939155698
accuracy:1.0,recall:1.0,precision:1.0,f1:1.0
FPR:0.0,FNR:0.0
TP:106.0,FP:0.0,TN:99.0,FN:0.0
-------------------------------------------
Dos9:
Test Loss per batch:0.0028636218048632145
accuracy:1.0,recall:1.0,precision:1.0,f1:1.0
FPR:0.0,FNR:0.0
TP:125.0,FP:0.0,TN:80.0,FN:0.0
-------------------------------------------
Dos10:
Test Loss per batch:0.0007114170002751052
accuracy:1.0,recall:1.0,precision:1.0,f1:1.0
FPR:0.0,FNR:0.0
TP:106.0,FP:0.0,TN:99.0,FN:0.0
-------------------------------------------
